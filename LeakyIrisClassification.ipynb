{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4e79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "import snntorch.functional as snnfunc\n",
    "import snntorch.spikegen as snngen\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbe04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\tdef __init__(self, beta = 0.5, threshold = 0.5, membrane_zero = 0.3):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.fll = nn.Linear(4, 4, bias = False)\n",
    "\t\tself.fsl = snn.Leaky(beta = beta, threshold = threshold,\n",
    "\t\t\t\t\t\t\t\t\tlearn_beta= True, \n",
    "\t\t\t\t\t\t\t\t\tlearn_threshold= True)\n",
    "\t\t\n",
    "\t\tself.sll = nn.Linear(4, 3, bias = False)\n",
    "\t\tself.ssl = snn.Leaky(beta = beta, threshold = threshold,\n",
    "\t\t\t\t\t\t\t\t\tlearn_beta= True, \n",
    "\t\t\t\t\t\t\t\t\tlearn_threshold= True)\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef forward(self, spk_input):\n",
    "\t\tmem1 = self.fsl.init_leaky()\n",
    "\t\tmem2 = self.ssl.init_leaky()\n",
    "\n",
    "\t\tspk_output = []\n",
    "\t\tfor step in range(spk_input.shape[1]):\n",
    "\t\t\tcur1 = self.fll(spk_input.to(torch.float32)[:, step])\n",
    "\t\t\tspk1, mem1 = self.fsl(cur1, mem1)\n",
    "\t\t\tcur2 = self.sll(spk1)\n",
    "\t\t\tspk2, mem2 = self.ssl(cur2, mem2)\n",
    "\t\t\t\n",
    "\t\t\tspk_output.append(spk2)\n",
    "\t\t\n",
    "\t\treturn torch.stack(spk_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24d4285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 150, 4])\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../iris_folder/Iris.csv\"\n",
    "df = pd.read_csv(filepath_or_buffer= file_path, sep= \",\", header= 0)\n",
    "df.drop(\"Id\", axis= 1, inplace= True)\n",
    "\n",
    "# преобразование датафрейма\n",
    "species = df[\"Species\"].unique()\n",
    "\n",
    "# При присваивании происходит изменение типа данных на object\n",
    "for i in range(len(species)):\n",
    "\tdf.loc[df[\"Species\"] == species[i], \"Species\"] = i\n",
    "df[\"Species\"] = df[\"Species\"].astype(\"int\")\n",
    "\n",
    "columns_headers = df.columns\n",
    "\n",
    "# Не учитываю species\n",
    "for header in columns_headers[:-1]:\n",
    "\t# Нормализую знеачения\n",
    "\tdf[header] = df[header] / df[header].max()\n",
    "# создание датасета для обучения\n",
    "data = []\n",
    "num_steps = 100\n",
    "\n",
    "for header in columns_headers:\n",
    "\tdata.append(torch.tensor(df[header].values))\n",
    "\n",
    "# Транспонируем тензор, чтобы иметь features и target каждого образца\n",
    "data = torch.stack(data, dim = 0).T\n",
    "\n",
    "trains = snngen.rate(data= data[:, :-1], num_steps= num_steps)\n",
    "\n",
    "# labels = snngen.targets_rate(data[:, -1], num_classes=3)\n",
    "labels = data[:, -1]\n",
    "print(trains.shape)\n",
    "# Возможно полная хрень. Требует проверки\n",
    "# Я уверен, что с осями какой-то косяк, так что придется переделывать при плохих результатах обучения\n",
    "trains = trains.permute(1, 0, 2)\n",
    "dataset = TensorDataset(trains, labels)\n",
    "train_data, test_data = random_split(dataset, [0.8, 0.2])\n",
    "train_data_loader = DataLoader(train_data, shuffle= True)\n",
    "test_data_loader = DataLoader(test_data, shuffle= True)\n",
    "lrng_rt = 5e-3\n",
    "\n",
    "epochs = 5\n",
    "net = Net()\n",
    "optim = torch.optim.Adam(net.parameters(), lr = lrng_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa3a13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0000\n",
      "Epoch 1, Loss: 0.0487\n",
      "Epoch 2, Loss: 0.1270\n",
      "Epoch 3, Loss: 0.0067\n",
      "Epoch 4, Loss: 0.0070\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\t\tfor trns, lbls in train_data_loader:\n",
    "\t\t\t\toptim.zero_grad()\n",
    "\t\t\t\toutputs = net(trns)\n",
    "\t\t\t\t\n",
    "\t\t\t\tloss_fn = snnfunc.loss.ce_count_loss()\n",
    "\t\t\t\tloss = loss_fn(spk_out=outputs, targets= lbls.to(torch.long))\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptim.step()\n",
    "\n",
    "\t\tprint((f\"Epoch {epoch}, Loss: {loss.item():.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d02a7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.97\n"
     ]
    }
   ],
   "source": [
    "# Testing accuracy\n",
    "data = []\n",
    "for trn, lbl in test_data_loader:\n",
    "\t\tprediction = net(trn)\n",
    "\t\tprediction = torch.mean(input= prediction.unsqueeze(0), dim = 1)\n",
    "\n",
    "\t\tdata.append([prediction.argmax().item(), lbl.item()])\n",
    "data = torch.tensor(data)\n",
    "accurate = data[(data[:, 0] == data[:, 1]), 0].numel()\n",
    "accuracy = accurate/data.shape[0]\n",
    "\n",
    "print((f\"accuracy : {accuracy:.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0edf6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fll.weight Parameter containing:\n",
      "tensor([[ 0.5107,  0.2889, -0.5308, -0.6423],\n",
      "        [ 0.0960, -0.0537,  0.3766,  0.0580],\n",
      "        [-0.1288, -0.5120,  0.4117,  0.0970],\n",
      "        [-0.3018, -0.7005, -0.2066, -0.2599]], requires_grad=True)\n",
      "fsl.threshold Parameter containing:\n",
      "tensor(0.4816, requires_grad=True)\n",
      "fsl.beta Parameter containing:\n",
      "tensor(0.3548, requires_grad=True)\n",
      "sll.weight Parameter containing:\n",
      "tensor([[ 0.7127, -0.1873, -0.7343, -0.3331],\n",
      "        [ 0.3311,  0.1809,  0.0866,  0.2750],\n",
      "        [-0.6120,  0.2930,  0.1601, -0.3958]], requires_grad=True)\n",
      "ssl.threshold Parameter containing:\n",
      "tensor(1.1666, requires_grad=True)\n",
      "ssl.beta Parameter containing:\n",
      "tensor(1.0154, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for par, val in net.named_parameters():\n",
    "    print(par, val)\n",
    "\n",
    "torch.save(net.state_dict(), \"fisher_iris_weights_leaky.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
