{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612bac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "import torch.nn.functional as nnfunc\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import ExpNeuron as en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241915c5",
   "metadata": {},
   "source": [
    "В данной модели используется следующая формула для вычисления мембранного потенциала:\n",
    "\\begin{equation}\n",
    "    U(t)=U_{0}\\exp(-\\beta t +\\sum_{i=0}^{t}I_{in}(i)),\n",
    "\\end{equation}\n",
    "Если $U(t) \\geq threshold$, то $U_{0} = U_{min}, t = 0$. Используется сумма спайков за время $t$, так как это упрощает вычисления и решает проблему \"мертового нейрона\" для входных спайков при малом U\".   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492224f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(nn.Module):\n",
    "\tdef __init__(self, beta, threshold, membrane_min, membrane_zero):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.fll = nn.Linear(1, 1, bias = False)\n",
    "\t\tself.nrn = en.ExpNeuron(\n",
    "\t\t\tbeta= beta,\n",
    "\t\t\tthreshold= threshold,\n",
    "\t\t\tmembrane_zero= membrane_zero,\n",
    "\t\t\tmembrane_min= membrane_min,\n",
    "\t\t\tlearn_beta= True,\n",
    "\t\t\tlearn_membrane_min= True,\n",
    "\t\t\tlearn_threshold= True)\n",
    "\t\t\n",
    "\t\n",
    "\tdef forward(self, spk_input):\n",
    "\t\tmem = self.nrn.init_neuron()\n",
    "\t\tspk_outpt = []\n",
    "\n",
    "\t\tfor step in range(spk_input.shape[1]):\n",
    "\t\t\tcur = self.fll(spk_input[:, step])\n",
    "\t\t\tspk, mem = self.nrn(cur, mem)\n",
    "\t\t\tspk_outpt.append(spk)\n",
    "\n",
    "\t\treturn torch.stack(spk_outpt, dim = 1) \n",
    "\t\n",
    "\t\n",
    "def gen_spike_train(lambda_, num_steps):\n",
    "\tspike_train = torch.tensor([1 if lambda_ > element else 0 for element in torch.rand(num_steps)], dtype=torch.float32)\n",
    "\treturn spike_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4accb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda = 0.95\n",
    "steps = 100\n",
    "samples = 200\n",
    "test_samples = 100\n",
    "eps = 5e-2\n",
    "btch_sz = 5\n",
    "\n",
    "\n",
    "gnrtr = torch.Generator().manual_seed(0)\n",
    "\n",
    "# Generating data in (a, b))\n",
    "a = 0.8\n",
    "b = 1\n",
    "if a > 0.8:\n",
    "\tlow_lambda_samples = int(samples * 0.3)\n",
    "\tlow_lambda_arr = torch.ones(low_lambda_samples).uniform_(0, 0.5)\n",
    "\tlambd_arr = torch.cat((torch.ones(samples - low_lambda_samples).uniform_(a, b), low_lambda_arr))\n",
    "else:\n",
    "\tlambd_arr = torch.ones(samples).uniform_(a, b)\n",
    "\n",
    "test_lambd_arr = torch.ones(test_samples).uniform_(0, 1)\n",
    "\n",
    "test_labels = ((abs(test_lambd_arr - Lambda) <= eps ) | (test_lambd_arr > Lambda)).float().unsqueeze(1)\n",
    "labels = ((abs(lambd_arr - Lambda) <= eps ) | (lambd_arr > Lambda)).float().unsqueeze(1)\n",
    "\n",
    "test_trains = torch.stack([gen_spike_train(lambd.item(), steps) for lambd in test_lambd_arr])\n",
    "trains = torch.stack([gen_spike_train(lambd.item(), steps) for lambd in lambd_arr])\n",
    "\n",
    "# train_data, test_data = random_split(TensorDataset(trains, labels), [samples * 80 // 100, samples * 20 // 100])\n",
    "train_data = TensorDataset(trains, labels)\n",
    "train_dataldr = DataLoader(dataset= train_data, batch_size= btch_sz)\n",
    "\n",
    "test_data = TensorDataset(test_trains, test_labels) \n",
    "test_dataldr = DataLoader(dataset = test_data, batch_size= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2e43e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor(0.7)\n",
    "threshold = torch.tensor(0.8)\n",
    "membrane_min = torch.tensor(0.8)\n",
    "membrane_zero = torch.tensor(0.6)\n",
    "\n",
    "lrng_rt = 5e-3\n",
    "\n",
    "epochs = 20\n",
    "neuron = Neuron(beta = beta, threshold = threshold, membrane_min = membrane_min, membrane_zero = membrane_zero)\n",
    "optim = torch.optim.Adam(neuron.parameters(), lr = lrng_rt, weight_decay= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e04ddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3089, Beta: 0.9307, Threshold: 0.7920, Membrane_min: 0.4281\n",
      "Epoch 5, Loss: 0.3089, Beta: 0.9307, Threshold: 0.7920, Membrane_min: 0.4280\n",
      "Epoch 10, Loss: 0.3089, Beta: 0.9307, Threshold: 0.7920, Membrane_min: 0.4280\n",
      "Epoch 15, Loss: 0.3089, Beta: 0.9307, Threshold: 0.7920, Membrane_min: 0.4280\n",
      "precision: 0.85, recall: 1.00, accuracy : 0.98\n",
      "\n",
      "true_positive: 11,\n",
      "true_negative: 87,\n",
      "false_negative: 0,\n",
      "false_positive: 2\n",
      "f1 metric: 0.917\n"
     ]
    }
   ],
   "source": [
    "# BCE - функция потерь\n",
    "for epoch in range(epochs):\n",
    "\t\tfor trns, lbls in train_dataldr:\n",
    "\t\t\t\toptim.zero_grad()\n",
    "\n",
    "\t\t\t\toutputs = neuron(trns.unsqueeze(-1))\n",
    "\t\t\t\tspike_cnt = outputs.mean(dim=1)\n",
    "\t\t\t\t\n",
    "\t\t\t\tloss = nnfunc.binary_cross_entropy(input= spike_cnt, target= lbls, reduction= \"mean\")\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptim.step()\n",
    "\n",
    "\t\t\t\twith torch.no_grad():\n",
    "\t\t\t\t\tneuron.nrn.beta.clamp_(min = 0.1)\n",
    "\t\t\t\t\tneuron.nrn.threshold.clamp_(min = 0.1)\n",
    "\t\t\t\t\tneuron.nrn.membrane_min.clamp_(min = 0.1)\n",
    "\n",
    "\n",
    "\t\tif epoch % 5 == 0:\n",
    "\t\t\tprint((f\"Epoch {epoch}, Loss: {loss.item():.4f}, \"\n",
    "\t\t\t\tf\"Beta: {neuron.nrn.beta.item():.4f}, Threshold: {neuron.nrn.threshold.item():.4f}, \"\n",
    "\t\t\t\tf\"Membrane_min: {neuron.nrn.membrane_min.item():.4f}\"))\n",
    "\t\t\n",
    "# Testing accuracy\n",
    "data = []\n",
    "for trn, lbl in test_dataldr:\n",
    "\t\tprediction = neuron(trn).mean(dim=1).item()\n",
    "\t\tdata.append([float(prediction > 0.5), lbl.item()])\n",
    "\t\t# print((f\"pred: {prediction:.2f}, predicted: {prediction > 0.5}, \"\n",
    "\t\t#        f\"true: {lbl}\"))\n",
    "data = torch.tensor(data)\n",
    "true_positive = data[(data[:, 0] == 1) & (data[:, 1] == 1), 0].numel()\n",
    "false_positive = data[(data[:, 0] == 1) & (data[:, 1] == 0), 0].numel()\n",
    "true_negative = data[(data[:, 0] == 0) & (data[:, 1] == 0), 0].numel()\n",
    "false_negative = data[(data[:, 0] == 0) & (data[:, 1] == 1), 0].numel()\n",
    "\n",
    "# Counting metrics\n",
    "if true_positive and true_negative: \n",
    "\t\tprecision = true_positive / (true_positive + false_positive)\n",
    "\t\trecall = true_positive / (true_positive + false_negative)\n",
    "\t\taccuracy = (true_positive + true_negative) / (true_positive + true_negative \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t+ false_positive + false_negative)\n",
    "\n",
    "\t\tprint((f\"precision: {precision:.2f}, recall: {recall:.2f}, accuracy : {accuracy:.2f}\"))\n",
    "\t\tprint((f\"\\ntrue_positive: {true_positive},\\n\"\n",
    "\t\t\t\tf\"true_negative: {true_negative},\\nfalse_negative: {false_negative},\\n\"\n",
    "\t\t\t\tf\"false_positive: {false_positive}\"))\n",
    "else:\n",
    "\t\tprint((f\"Low accuracy of the model.\\ntrue_positive: {true_positive},\\n\"\n",
    "\t\t\t\tf\"true_negative: {true_negative},\\nfalse_negative: {false_negative},\\n\"\n",
    "\t\t\t\tf\"false_positive: {false_positive}\"))\n",
    "\t\n",
    "if precision and recall:\n",
    "\t\tf1 = 2 * precision * recall / (precision + recall)\n",
    "\t\tprint(f\"f1 metric: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8798080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fll.weight Parameter containing:\n",
      "tensor([[0.6245]], requires_grad=True)\n",
      "nrn.threshold Parameter containing:\n",
      "tensor(0.7920, requires_grad=True)\n",
      "nrn.beta Parameter containing:\n",
      "tensor(0.9307, requires_grad=True)\n",
      "nrn.membrane_min Parameter containing:\n",
      "tensor(0.4323, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for par, val in neuron.named_parameters():\n",
    "\tprint(par, val)\n",
    "\n",
    "# torch.save(neuron.state_dict(), \"binary_classification_weights.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
