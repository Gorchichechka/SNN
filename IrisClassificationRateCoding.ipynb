{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ExpNeuron as en\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "import snntorch.functional as snnfunc\n",
    "import snntorch.spikegen as snngen\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\tdef __init__(self, \n",
    "\t\t\tbeta_first = 0.8, threshold_first = 0.7, membrane_zero_first = 0.2, membrane_min_first = 0.3,\n",
    "\t\t\tlearn_beta_first = False, learn_threshold_first = False, learn_membrane_min_first = False,\n",
    "\t\t\tbeta_second = 0.8, threshold_second = 0.5, membrane_zero_second = 0.2, membrane_min_second = 0.3,\n",
    "\t\t\tlearn_beta_second = False, learn_threshold_second = False, learn_membrane_min_second = False\n",
    "\t\t\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.fll = nn.Linear(4, 4, bias = False)\n",
    "\t\tself.fsl = en.ExpNeuron(beta = beta_first, threshold = threshold_first,\n",
    "\t\t\t\t\t\t\t\t   \tmembrane_zero= membrane_zero_first,\n",
    "\t\t\t\t\t\t\t\t\tmembrane_min = membrane_min_first,\n",
    "\t\t\t\t\t\t\t\t\tlearn_beta= learn_beta_first, \n",
    "\t\t\t\t\t\t\t\t\tlearn_threshold= learn_threshold_first,\n",
    "\t\t\t\t\t\t\t\t\tlearn_membrane_min= learn_membrane_min_first)\n",
    "\t\t\n",
    "\t\tself.sll = nn.Linear(4, 3, bias = False)\n",
    "\t\tself.ssl = en.ExpNeuron(beta = beta_second, threshold = threshold_second,\n",
    "\t\t\t\t\t\t\t\t   \tmembrane_zero= membrane_zero_second,\n",
    "\t\t\t\t\t\t\t\t\tmembrane_min = membrane_min_second,\n",
    "\t\t\t\t\t\t\t\t\tlearn_beta= learn_beta_second, \n",
    "\t\t\t\t\t\t\t\t\tlearn_threshold= learn_threshold_second,\n",
    "\t\t\t\t\t\t\t\t\tlearn_membrane_min= learn_membrane_min_second)\n",
    "\t\t\n",
    "\tdef forward(self, spk_input):\n",
    "\t\tmem1 = self.fsl.init_neuron()\n",
    "\t\tmem2 = self.ssl.init_neuron()\n",
    "\n",
    "\t\tspk_output = []\n",
    "\t\tfor step in range(spk_input.shape[1]):\n",
    "\t\t\tcur1 = self.fll(spk_input.to(torch.float32)[:, step])\n",
    "\t\t\tspk1, mem1 = self.fsl(cur1, mem1)\n",
    "\t\t\tcur2 = self.sll(spk1)\n",
    "\t\t\tspk2, mem2 = self.ssl(cur2, mem2)\n",
    "\t\t\t\n",
    "\t\t\tspk_output.append(spk2)\n",
    "\t\t\n",
    "\t\treturn torch.stack(spk_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bac1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../iris_folder/Iris.csv\"\n",
    "df = pd.read_csv(filepath_or_buffer= file_path, sep= \",\", header= 0)\n",
    "df.drop(\"Id\", axis= 1, inplace= True)\n",
    "\n",
    "# преобразование датафрейма\n",
    "species = df[\"Species\"].unique()\n",
    "\n",
    "# При присваивании происходит изменение типа данных на object\n",
    "for i in range(len(species)):\n",
    "\tdf.loc[df[\"Species\"] == species[i], \"Species\"] = i\n",
    "df[\"Species\"] = df[\"Species\"].astype(\"int\")\n",
    "\n",
    "columns_headers = df.columns\n",
    "\n",
    "# Не учитываю species\n",
    "for header in columns_headers[:-1]:\n",
    "\t# Нормализую знеачения\n",
    "\tdf[header] = df[header] / df[header].max()\n",
    "# создание датасета для обучения\n",
    "data = []\n",
    "num_steps = 100\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "for header in columns_headers:\n",
    "\tdata.append(torch.tensor(df[header].values))\n",
    "\n",
    "# Транспонируем тензор, чтобы иметь features и target каждого образца\n",
    "data = torch.stack(data, dim = 0).T\n",
    "\n",
    "trains = snngen.rate(data= data[:, :-1], num_steps= num_steps)\n",
    "\n",
    "# labels = snngen.targets_rate(data[:, -1], num_classes=3)\n",
    "labels = data[:, -1]\n",
    "# Возможно полная хрень. Требует проверки\n",
    "# Я уверен, что с осями какой-то косяк, так что придется переделывать при плохих результатах обучения\n",
    "trains = trains.permute(1, 0, 2)\n",
    "dataset = TensorDataset(trains, labels)\n",
    "train_data, test_data = random_split(dataset, [0.8, 0.2])\n",
    "train_data_loader = DataLoader(train_data, shuffle= True, batch_size=batch_size)\n",
    "test_data_loader = DataLoader(test_data, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fded714",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "states = []\n",
    "size = 5\n",
    "\n",
    "params = [[torch.concatenate([torch.rand(3).clamp(min = 0.3), torch.Tensor([0.2])]) for i in range(2)] for _ in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(size):\n",
    "\tprint(f\"Net numb: {i}. Parameters: {params[i]}\")\n",
    "\tlrng_rt = 1e-2\n",
    "\n",
    "\tnet = Net(\n",
    "\t\t\tbeta_first = params[i][0][0], threshold_first = params[i][0][1], membrane_zero_first = params[i][0][2], membrane_min_first = params[i][0][3],\n",
    "\t\t\tlearn_beta_first = False, learn_threshold_first = False, learn_membrane_min_first = True,\n",
    "\t\t\tbeta_second = params[i][1][0], threshold_second = params[i][1][1], membrane_zero_second = params[i][1][2], membrane_min_second = params[i][1][3],\n",
    "\t\t\tlearn_beta_second = False, learn_threshold_second = False, learn_membrane_min_second = True\n",
    "\t\t)\n",
    "\n",
    "\toptim = torch.optim.AdamW(net.parameters(), lr = lrng_rt)\n",
    "\tloss_fn = snnfunc.loss.mse_count_loss(correct_rate=0.3, incorrect_rate= 0.1, num_classes=3)\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\n",
    "\t\tif epoch == 10: lrng_rt = 1e-3\n",
    "\n",
    "\t\tfor trns, lbls in train_data_loader:\n",
    "\t\t\t\toptim.zero_grad()\n",
    "\t\t\t\toutputs = net(trns)\n",
    "\n",
    "\t\t\t\tloss = loss_fn(spk_out=outputs, targets= lbls.to(torch.long))\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptim.step()\n",
    "\n",
    "\n",
    "\t\tprint((f\"Epoch {epoch}, Loss: {loss.item():.4f}\"))\n",
    "\n",
    "\t\t# Testing accuracy\n",
    "\t\tdata = []\n",
    "\t\tfor trn, lbl in test_data_loader:\n",
    "\t\t\t\tprediction = net(trn)\n",
    "\t\t\t\tprediction = torch.mean(input= prediction.unsqueeze(0), dim = 1)\n",
    "\n",
    "\t\t\t\tdata.append([prediction.argmax().item(), lbl.item()])\n",
    "\t\t\t\t\n",
    "\t\tdata = torch.tensor(data)\n",
    "\t\taccurate = data[(data[:, 0] == data[:, 1]), 0].numel()\n",
    "\t\taccuracy = accurate/data.shape[0]\n",
    "\n",
    "\t\tif accuracy >= 0.9:\n",
    "\t\t\tstates.append(net.state_dict())\n",
    "\n",
    "\t\tprint((f\"accuracy : {accuracy:.2f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da97d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for state in states:\n",
    "    load_net = Net()\n",
    "    load_net.load_state_dict(state)\n",
    "\n",
    "    # Testing accuracy\n",
    "    data = []\n",
    "    for trn, lbl in test_data_loader:\n",
    "            prediction = load_net(trn)\n",
    "            prediction = torch.mean(input= prediction.unsqueeze(0), dim = 1)\n",
    "\n",
    "            data.append([prediction.argmax().item(), lbl.item()])\n",
    "            \n",
    "    data = torch.tensor(data)\n",
    "    accurate = data[(data[:, 0] == data[:, 1]), 0].numel()\n",
    "    accuracy = accurate/data.shape[0]\n",
    "\n",
    "    print((f\"accuracy : {accuracy:.2f}\"))\n",
    "    acc.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29614202",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = torch.tensor(acc)\n",
    "max_acc_idx = torch.argmax(acc, dim = 0)\n",
    "\n",
    "torch.save(states[max_acc_idx], \"Iris_ExpNeuron_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for par, val in net.named_parameters():\n",
    "#     print(par, val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
