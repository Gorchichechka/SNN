{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409c7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ExpNeuron as en\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "import snntorch.functional as snnfunc\n",
    "import snntorch.spikegen as snngen\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\tdef __init__(self, beta = 0.5, threshold = 0.5, membrane_zero = 0.3):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.fll = nn.Linear(4, 4, bias = False)\n",
    "\t\tself.fsl = en.ExpNeuron(beta = beta, threshold = threshold,\n",
    "\t\t\t\t\t\t\t\t   \tmembrane_zero= membrane_zero,\n",
    "\t\t\t\t\t\t\t\t\tlearn_beta= True, \n",
    "\t\t\t\t\t\t\t\t\tlearn_threshold= True, \n",
    "\t\t\t\t\t\t\t\t\tlearn_membrane_min= True)\n",
    "\t\t\n",
    "\t\tself.sll = nn.Linear(4, 3, bias = False)\n",
    "\t\tself.ssl = en.ExpNeuron(beta = beta, threshold = threshold,\n",
    "\t\t\t\t\t\t\t\t   \tmembrane_zero= membrane_zero,\n",
    "\t\t\t\t\t\t\t\t\tlearn_beta= True, \n",
    "\t\t\t\t\t\t\t\t\tlearn_threshold= True, \n",
    "\t\t\t\t\t\t\t\t\tlearn_membrane_min= True)\n",
    "\t\t\n",
    "\t\t# self.fll.weight.data.clamp_(min=0.05)\n",
    "\t\t# self.sll.weight.data.clamp_(min=0.05)\n",
    "\t\t\n",
    "\tdef forward(self, spk_input):\n",
    "\t\tmem1 = self.fsl.init_neuron()\n",
    "\t\tmem2 = self.ssl.init_neuron()\n",
    "\n",
    "\t\tspk_output = []\n",
    "\t\tfor step in range(spk_input.shape[1]):\n",
    "\t\t\tcur1 = self.fll(spk_input.to(torch.float32)[:, step])\n",
    "\t\t\tspk1, mem1 = self.fsl(cur1, mem1)\n",
    "\t\t\tcur2 = self.sll(spk1)\n",
    "\t\t\tspk2, mem2 = self.ssl(cur2, mem2)\n",
    "\t\t\t\n",
    "\t\t\tspk_output.append(spk2)\n",
    "\t\t\n",
    "\t\treturn torch.stack(spk_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bac1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../iris_folder/Iris.csv\"\n",
    "df = pd.read_csv(filepath_or_buffer= file_path, sep= \",\", header= 0)\n",
    "df.drop(\"Id\", axis= 1, inplace= True)\n",
    "\n",
    "# преобразование датафрейма\n",
    "species = df[\"Species\"].unique()\n",
    "\n",
    "# При присваивании происходит изменение типа данных на object\n",
    "for i in range(len(species)):\n",
    "\tdf.loc[df[\"Species\"] == species[i], \"Species\"] = i\n",
    "df[\"Species\"] = df[\"Species\"].astype(\"int\")\n",
    "\n",
    "columns_headers = df.columns\n",
    "\n",
    "# Не учитываю species\n",
    "for header in columns_headers[:-1]:\n",
    "\t# Нормализую знеачения\n",
    "\tdf[header] = df[header] / df[header].max()\n",
    "# создание датасета для обучения\n",
    "data = []\n",
    "num_steps = 100\n",
    "\n",
    "for header in columns_headers:\n",
    "\tdata.append(torch.tensor(df[header].values))\n",
    "\n",
    "# Транспонируем тензор, чтобы иметь features и target каждого образца\n",
    "data = torch.stack(data, dim = 0).T\n",
    "\n",
    "trains = snngen.rate(data= data[:, :-1], num_steps= num_steps)\n",
    "\n",
    "# labels = snngen.targets_rate(data[:, -1], num_classes=3)\n",
    "labels = data[:, -1]\n",
    "print(trains.shape)\n",
    "# Возможно полная хрень. Требует проверки\n",
    "# Я уверен, что с осями какой-то косяк, так что придется переделывать при плохих результатах обучения\n",
    "trains = trains.permute(1, 0, 2)\n",
    "dataset = TensorDataset(trains, labels)\n",
    "train_data, test_data = random_split(dataset, [0.8, 0.2])\n",
    "train_data_loader = DataLoader(train_data, shuffle= True)\n",
    "test_data_loader = DataLoader(test_data, shuffle= True)\n",
    "lrng_rt = 5e-3\n",
    "\n",
    "epochs = 5\n",
    "net = Net()\n",
    "optim = torch.optim.Adam(net.parameters(), lr = lrng_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "672d1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.1269\n",
      "Epoch 1, Loss: 0.1269\n",
      "Epoch 2, Loss: 1.0986\n",
      "Epoch 3, Loss: 3.0486\n",
      "Epoch 4, Loss: 0.0550\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\t\tfor trns, lbls in train_data_loader:\n",
    "\t\t\t\toptim.zero_grad()\n",
    "\t\t\t\toutputs = net(trns)\n",
    "\t\t\t\t\n",
    "\t\t\t\tloss_fn = snnfunc.loss.ce_count_loss()\n",
    "\t\t\t\tloss = loss_fn(spk_out=outputs, targets= lbls.to(torch.long))\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptim.step()\n",
    "\n",
    "\t\t\t\t# net.fll.weight.data.clamp_(min=0.05)\n",
    "\t\t\t\t# net.sll.weight.data.clamp_(min=0.05)\n",
    "\n",
    "\t\tprint((f\"Epoch {epoch}, Loss: {loss.item():.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing accuracy\n",
    "data = []\n",
    "for trn, lbl in test_data_loader:\n",
    "\t\tprediction = net(trn)\n",
    "\t\tprediction = torch.mean(input= prediction.unsqueeze(0), dim = 1)\n",
    "\n",
    "\t\tdata.append([prediction.argmax().item(), lbl.item()])\n",
    "data = torch.tensor(data)\n",
    "accurate = data[(data[:, 0] == data[:, 1]), 0].numel()\n",
    "accuracy = accurate/data.shape[0]\n",
    "\n",
    "print((f\"accuracy : {accuracy:.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde3370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fll.weight Parameter containing:\n",
      "tensor([[0.0500, 0.0500, 0.0618, 0.0765],\n",
      "        [0.4804, 0.1619, 0.9437, 1.2211],\n",
      "        [0.0938, 0.0762, 0.6437, 0.8028],\n",
      "        [0.0500, 0.2858, 0.0505, 0.1506]], requires_grad=True)\n",
      "fsl.threshold Parameter containing:\n",
      "tensor(1.3287, requires_grad=True)\n",
      "fsl.beta Parameter containing:\n",
      "tensor(0.7791, requires_grad=True)\n",
      "fsl.membrane_min Parameter containing:\n",
      "tensor(0.4176, requires_grad=True)\n",
      "sll.weight Parameter containing:\n",
      "tensor([[0.3084, 0.6793, 0.5332, 0.1823],\n",
      "        [0.4148, 0.0708, 0.5344, 0.0545],\n",
      "        [0.0500, 0.1883, 0.0500, 0.0823]], requires_grad=True)\n",
      "ssl.threshold Parameter containing:\n",
      "tensor(-0.0929, requires_grad=True)\n",
      "ssl.beta Parameter containing:\n",
      "tensor(0.2737, requires_grad=True)\n",
      "ssl.membrane_min Parameter containing:\n",
      "tensor(-0.4422, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for par, val in net.named_parameters():\n",
    "    print(par, val)\n",
    "\n",
    "# torch.save(net.state_dict(), \"fisher_iris_weights.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
